{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all the required packages which include Tensorflow and Keras\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting the classifier there are two option either go with sequential or functional\n",
    "classifier = Sequential()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding convolutional and Maxpooling layer with the activation center relu\n",
    "#input shape we are taking as 64*64 with RGB\n",
    "#we are having 32 different filetrs and sliding size is 3*3\n",
    "\n",
    "classifier.add(Conv2D(32, (3, 3), input_shape = (64, 64, 3), activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#maxpooling is having slide size 2*2\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding multiple layers for multilayer feed back neural network\n",
    "classifier.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the extracted features in one dimensional array\n",
    "classifier.add(Flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "#densing the feature to make classified clustering\n",
    "classifier.add(Dense(activation = 'relu',units=128))\n",
    "classifier.add(Dense(activation = 'sigmoid',units=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the images in training and testing objects with some preprocesing \n",
    "from keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/telraswa/Desktop/Swapnil/Pallavi/Deep_Learning/CNN\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "os.getcwd()\n",
    "os.chdir('/home/telraswa/Desktop/Swapnil/Pallavi/Deep_Learning/CNN')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 539 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = train_datagen.flow_from_directory('/home/telraswa/Desktop/Swapnil/Pallavi/Deep_Learning/CNN/Train',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 44 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_set = test_datagen.flow_from_directory('/home/telraswa/Desktop/Swapnil/Pallavi/Deep_Learning/CNN/Test',\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "17/17 [==============================] - 4s 246ms/step - loss: 0.5421 - acc: 0.7955 - val_loss: 1.5664 - val_acc: 0.5000\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 4s 235ms/step - loss: 0.5423 - acc: 0.8026 - val_loss: 1.1679 - val_acc: 0.5000\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 4s 228ms/step - loss: 0.5020 - acc: 0.8013 - val_loss: 0.9968 - val_acc: 0.5000\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 4s 231ms/step - loss: 0.4951 - acc: 0.8016 - val_loss: 1.1710 - val_acc: 0.5000\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 4s 232ms/step - loss: 0.4881 - acc: 0.8022 - val_loss: 1.1218 - val_acc: 0.5000\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 4s 233ms/step - loss: 0.4731 - acc: 0.8010 - val_loss: 1.1291 - val_acc: 0.5000\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 4s 234ms/step - loss: 0.4731 - acc: 0.8022 - val_loss: 1.1073 - val_acc: 0.5000\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 4s 231ms/step - loss: 0.4756 - acc: 0.8019 - val_loss: 1.1974 - val_acc: 0.5000\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 4s 233ms/step - loss: 0.4614 - acc: 0.8016 - val_loss: 1.3262 - val_acc: 0.5000\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 4s 231ms/step - loss: 0.4589 - acc: 0.8038 - val_loss: 1.3316 - val_acc: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1db9382e50>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setting some parameters to feed back neural network \n",
    "\n",
    "classifier.fit_generator(training_set, steps_per_epoch=None, epochs=10, verbose=1, callbacks=None, validation_data=test_set, validation_steps=None, class_weight=None, max_queue_size=10, workers=1, use_multiprocessing=False, shuffle=True, initial_epoch=0)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading validation image\n",
    "import numpy as np\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=64x64 at 0x7F1DB920E150>"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_image = image.load_img('/home/telraswa/Desktop/Swapnil/Pallavi/Deep_Learning/validation/45.jpg', target_size = (64, 64))\n",
    "validation_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting image to numeric matrix \n",
    "validation_image = image.img_to_array(validation_image)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[  0.,  13., 109.],\n",
       "         [ 69., 117., 193.],\n",
       "         [ 45., 107., 218.],\n",
       "         ...,\n",
       "         [ 37., 130., 233.],\n",
       "         [ 46., 121., 222.],\n",
       "         [ 74., 127., 223.]],\n",
       "\n",
       "        [[ 65., 120., 221.],\n",
       "         [169., 124.,  57.],\n",
       "         [ 21.,   1.,   0.],\n",
       "         ...,\n",
       "         [ 56.,  37.,  23.],\n",
       "         [ 37.,  20.,   2.],\n",
       "         [ 10.,   0.,   0.]],\n",
       "\n",
       "        [[ 60., 120., 192.],\n",
       "         [227., 185., 145.],\n",
       "         [ 14.,   0.,   0.],\n",
       "         ...,\n",
       "         [ 68.,  43.,  12.],\n",
       "         [ 29.,  12.,   0.],\n",
       "         [230., 188., 138.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 56., 126., 221.],\n",
       "         [  0.,   0.,   0.],\n",
       "         [  0.,   0.,   0.],\n",
       "         ...,\n",
       "         [  0.,   0.,   0.],\n",
       "         [  0.,   0.,   0.],\n",
       "         [  0.,   0.,   0.]],\n",
       "\n",
       "        [[ 56., 126., 221.],\n",
       "         [  0.,   0.,   0.],\n",
       "         [  0.,   0.,   0.],\n",
       "         ...,\n",
       "         [  0.,   0.,   0.],\n",
       "         [  0.,   0.,   0.],\n",
       "         [  0.,   0.,   0.]],\n",
       "\n",
       "        [[ 59., 125., 221.],\n",
       "         [  0.,   0.,   0.],\n",
       "         [  0.,   0.,   0.],\n",
       "         ...,\n",
       "         [  0.,   0.,   0.],\n",
       "         [  0.,   0.,   0.],\n",
       "         [  0.,   0.,   0.]]]], dtype=float32)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_image = np.expand_dims(validation_image, axis = 0)\n",
    "validation_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.]], dtype=float32)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = classifier.predict(validation_image)\n",
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Abnormal': 0, 'Normal': 1}"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#finding the indices from train images for different classes\n",
    "training_set.class_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "if result[0][0] == 1:\n",
    "    prediction = 'Normal'\n",
    "else:\n",
    "    prediction = 'Abnormal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Condition of patient is :', 'Abnormal')\n"
     ]
    }
   ],
   "source": [
    "#final prediction \n",
    "print(\"Condition of patient is :\",prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
